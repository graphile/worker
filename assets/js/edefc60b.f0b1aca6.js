"use strict";(self.webpackChunkgraphile_worker=self.webpackChunkgraphile_worker||[]).push([[3624],{9916:(e,n,t)=>{t.d(n,{xA:()=>u,yg:()=>h});var r=t(3696);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function a(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?a(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,r,o=function(e,n){if(null==e)return{};var t,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)t=a[r],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)t=a[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var l=r.createContext({}),c=function(e){var n=r.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},u=function(e){var n=c(e.components);return r.createElement(l.Provider,{value:n},e.children)},p="mdxType",g={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},d=r.forwardRef((function(e,n){var t=e.components,o=e.mdxType,a=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),p=c(t),d=o,h=p["".concat(l,".").concat(d)]||p[d]||g[d]||a;return t?r.createElement(h,i(i({ref:n},u),{},{components:t})):r.createElement(h,i({ref:n},u))}));function h(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var a=t.length,i=new Array(a);i[0]=d;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s[p]="string"==typeof e?e:o,i[1]=s;for(var c=2;c<a;c++)i[c]=t[c];return r.createElement.apply(null,i)}return r.createElement.apply(null,t)}d.displayName="MDXCreateElement"},4974:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>g,frontMatter:()=>a,metadata:()=>s,toc:()=>c});var r=t(8102),o=(t(3696),t(9916));const a={title:"Performance",sidebar_position:120},i=void 0,s={unversionedId:"performance",id:"performance",title:"Performance",description:"Quick stats",source:"@site/docs/performance.md",sourceDirName:".",slug:"/performance",permalink:"/docs/performance",draft:!1,editUrl:"https://github.com/graphile/worker/tree/main/website/docs/performance.md",tags:[],version:"current",sidebarPosition:120,frontMatter:{title:"Performance",sidebar_position:120},sidebar:"tutorialSidebar",previous:{title:"Forbidden flags",permalink:"/docs/forbidden-flags"},next:{title:"Error handling",permalink:"/docs/error-handling"}},l={},c=[{value:"Quick stats",id:"quick-stats",level:2},{value:"Performance statement",id:"performance-statement",level:2},{value:"Horizontal scaling",id:"horizontal-scaling",level:2},{value:"Enabling batching for highest performance",id:"enabling-batching-for-highest-performance",level:2},{value:"Running the performance tests",id:"running-the-performance-tests",level:2},{value:"perfTest results:",id:"perftest-results",level:2},{value:"With batching",id:"with-batching",level:3},{value:"Without batching",id:"without-batching",level:3}],u={toc:c},p="wrapper";function g(e){let{components:n,...t}=e;return(0,o.yg)(p,(0,r.A)({},u,t,{components:n,mdxType:"MDXLayout"}),(0,o.yg)("h2",{id:"quick-stats"},"Quick stats"),(0,o.yg)("p",null,"Quick stats in optimial conditions:"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"jobs executed per second: ~183,000"),(0,o.yg)("li",{parentName:"ul"},"average latency from add_job to job execution start: 4.16ms (max: 13.84ms)"),(0,o.yg)("li",{parentName:"ul"},"jobs queued per second from single add_jobs batch call: ~202,000"),(0,o.yg)("li",{parentName:"ul"},"time to start and immediately shut down the worker: 68ms")),(0,o.yg)("p",null,"The above stats were achieved with this configuration:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-ts"},'const preset = {\n  worker: {\n    connectionString: "postgres:///graphile_worker_perftest",\n    fileExtensions: [".js", ".cjs", ".mjs"],\n\n    concurrentJobs: 24,\n    maxPoolSize: 25,\n\n    // Batching options (see below)\n    localQueue: { size: 500 },\n    completeJobBatchDelay: 0,\n    failJobBatchDelay: 0,\n  },\n};\n')),(0,o.yg)("h2",{id:"performance-statement"},"Performance statement"),(0,o.yg)("p",null,(0,o.yg)("inlineCode",{parentName:"p"},"graphile-worker")," is not intended to replace extremely high performance\ndedicated job queues for Facebook scale, it","'","s intended to give regular\norganizations the fastest and easiest to set up job queue we can achieve without\nneeding to expand your infrastructure beyond Node.js and PostgreSQL. But this\ndoesn","'","t mean it","'","s a slouch by any means ","\u2014"," it achieves an average\nlatency from triggering a job in one process to executing it in another of under\n5ms, and a well-specced database server can queue around 172,000 jobs per second\nfrom a single PostgreSQL client, and can process around 196k jobs per second\nusing a pool of 4 Graphile Worker instances, each with concurrency set to 24.\nFor many organizations, this is more than they'll ever need."),(0,o.yg)("h2",{id:"horizontal-scaling"},"Horizontal scaling"),(0,o.yg)("p",null,(0,o.yg)("inlineCode",{parentName:"p"},"graphile-worker")," is horizontally scalable to a point. Each instance has a\ncustomizable worker pool, this pool defaults to size 1 (only one job at a time\non this worker) but depending on the nature of your tasks (i.e. assuming\nthey","'","re not compute-heavy) you will likely want to set this higher to\nbenefit from Node.js","'"," concurrency. If your tasks are compute heavy you may\nstill wish to set it higher and then using Node","'","s ",(0,o.yg)("inlineCode",{parentName:"p"},"child_process")," or\n",(0,o.yg)("inlineCode",{parentName:"p"},"worker_threads")," to share the compute load over multiple cores without\nsignificantly impacting the main worker","'","s run loop."),(0,o.yg)("h2",{id:"enabling-batching-for-highest-performance"},"Enabling batching for highest performance"),(0,o.yg)("p",null,"Graphile Worker is limited by the performance of the underlying Postgres\ndatabase, and when you hit this limit performance will start to go down (rather\nthan up) as you add more workers."),(0,o.yg)("p",null,"To mitigate this, we've added batching functionality to many of the internal\nmethods which you can enable via the configuration. For example using a local\nqueue enables each pool to pull down a configurable number of jobs up front so\nits workers can start a new job the moment their previous one completes without\nhaving to request a new job from the database. This batching also reduces load\non the database since there are fewer total queries per second, but it's a\nslight trade-off since more jobs are checked out but not necessarily actively\nbeing worked on, so latency may increase and in the event of a crash more jobs\nwill be locked."),(0,o.yg)("h2",{id:"running-the-performance-tests"},"Running the performance tests"),(0,o.yg)("p",null,"To test performance, you can check out the repository and then run\n",(0,o.yg)("inlineCode",{parentName:"p"},"yarn perfTest"),". This runs three tests:"),(0,o.yg)("ol",null,(0,o.yg)("li",{parentName:"ol"},"a startup/shutdown test to see how fast the worker can startup and exit if\nthere","'","s no jobs queued (this includes connecting to the database and\nensuring the migrations are up to date)"),(0,o.yg)("li",{parentName:"ol"},"a load test ","\u2014"," by default this will run 200,000\n",(0,o.yg)("a",{parentName:"li",href:"https://github.com/graphile/worker/blob/main/perfTest/tasks/log_if_999.js"},"trivial"),"\njobs with a parallelism of 4 (i.e. 4 node processes) and a concurrency of 24\n(i.e. 24 concurrent jobs running on each node process), but you can configure\nthis in ",(0,o.yg)("inlineCode",{parentName:"li"},"perfTest/run.js"),". (These settings were optimized for a Intel\ni9-14900K with efficiency cores disabled and running both the tests and the\ndatabase locally.)"),(0,o.yg)("li",{parentName:"ol"},"a latency test ","\u2014"," determining how long between issuing an ",(0,o.yg)("inlineCode",{parentName:"li"},"add_job"),"\ncommand and the task itself being executed.")),(0,o.yg)("h2",{id:"perftest-results"},"perfTest results:"),(0,o.yg)("p",null,"Executed on\n",(0,o.yg)("a",{parentName:"p",href:"https://uk.pcpartpicker.com/user/BenjieGillam/saved/#view=BjtCrH"},"this machine"),",\nrunning both the workers and the database (and a tonne of Chrome tabs, electron\napps, and what not)."),(0,o.yg)("h3",{id:"with-batching"},"With batching"),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Jobs per second: ~184,000")),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-ts"},'const preset = {\n  worker: {\n    connectionString: "postgres:///graphile_worker_perftest",\n    fileExtensions: [".js", ".cjs", ".mjs"],\n\n    concurrentJobs: 24,\n    maxPoolSize: 25,\n\n    // Batching options (see below)\n    localQueue: { size: 500 },\n    completeJobBatchDelay: 0,\n    failJobBatchDelay: 0,\n  },\n};\n')),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre"},"Timing startup/shutdown time...\n... it took 68ms\n\nScheduling 200000 jobs\nAdding jobs: 988.425ms\n... it took 1160ms\n\n\nTiming 200000 job execution...\nFound 999!\n\n... it took 1156ms\nJobs per second: 183895.49\n\nTesting latency...\n[core] INFO: Worker connected and looking for jobs... (task names: 'latency')\nBeginning latency test\nLatencies - min: 3.24ms, max: 18.18ms, avg: 4.28ms\n")),(0,o.yg)("h3",{id:"without-batching"},"Without batching"),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Jobs per second: ~15,600")),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-ts"},'const preset = {\n  worker: {\n    connectionString: "postgres:///graphile_worker_perftest",\n    fileExtensions: [".js", ".cjs", ".mjs"],\n\n    concurrentJobs: 24,\n    maxPoolSize: 25,\n\n    // Batching disabled (default)\n    localQueue: { size: -1 },\n    completeJobBatchDelay: -1,\n    failJobBatchDelay: -1,\n  },\n};\n')),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre"},"Timing startup/shutdown time...\n... it took 77ms\n\n\nScheduling 200000 jobs\nAdding jobs: 992.368ms\n... it took 1163ms\n\n\nTiming 200000 job execution...\nFound 999!\n\n... it took 12892ms\nJobs per second: 15606.79\n\n\nTesting latency...\n[core] INFO: Worker connected and looking for jobs... (task names: 'latency')\nBeginning latency test\nLatencies - min: 3.40ms, max: 14.13ms, avg: 4.47ms\n")),(0,o.yg)("p",null,"TODO: post perfTest results in a more reasonable configuration, e.g. using an\nRDS PostgreSQL server and a worker running on EC2."))}g.isMDXComponent=!0}}]);